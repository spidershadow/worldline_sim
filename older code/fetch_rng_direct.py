#!/usr/bin/env python3
"""
fetch_rng_direct.py
-------------------
Fetches Global Consciousness Project data directly from their data endpoint
and calculates the average absolute z-values for each year.

Uses format: 
https://noosphere.princeton.edu/cgi-bin/eggdatareq.pl?z=1&year=YYYY&month=MM&day=DD&stime=00%3A00%3A00&etime=23%3A59%3A59&gzip=Yes&idate=Yes

Output:
- data/rng_direct_avg_abs_z.csv: Annual average of |z| values
"""

import datetime as dt
import io
import pathlib
import sys
import time
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import requests
from tqdm import tqdm

# Where the final CSV will be stored
DATA_DIR = pathlib.Path("data")
DATA_DIR.mkdir(exist_ok=True)

# Base URL for direct GCP data access
BASE_URL = "https://noosphere.princeton.edu/cgi-bin/eggdatareq.pl?z=1&year={year}&month={month}&day={day}&stime=00%3A00%3A00&etime=23%3A59%3A59&gzip=Yes&idate=Yes"

# Fallback values ensure the simulator works offline / if a download fails
FALLBACK = {
    1998: 0.806, 1999: 0.799, 2000: 0.801, 2001: 0.797, 2002: 0.801,
    2003: 0.800, 2004: 0.798, 2005: 0.796, 2006: 0.801, 2007: 0.799,
    2008: 0.800, 2009: 0.799, 2010: 0.804, 2011: 0.801, 2012: 0.800,
    2013: 0.798, 2014: 0.797, 2015: 0.799, 2016: 0.802, 2017: 0.798,
    2018: 0.799, 2019: 0.801, 2020: 0.797, 2021: 0.794, 2022: 0.795,
    2023: 0.792, 2024: 0.793,
}


def fetch_day_data(year: int, month: int, day: int) -> Optional[pd.DataFrame]:
    """Fetch raw RNG data for a specific day and calculate z-scores.
    
    Args:
        year: Year to fetch
        month: Month to fetch
        day: Day to fetch
        
    Returns:
        DataFrame of processed data or None if download failed
    """
    url = BASE_URL.format(year=year, month=month, day=day)
    
    try:
        resp = requests.get(url, timeout=40)
        resp.raise_for_status()
        
        # Process the raw data
        lines = resp.text.strip().split('\n')
        
        # Extract data rows (starting with '13')
        data_rows = []
        for line in lines:
            if line.startswith('13,'):
                parts = line.split(',')
                if len(parts) < 3:  # Need at least timestamp and one value
                    continue
                    
                # Extract timestamp and values
                timestamp = parts[1]
                values = [float(v) for v in parts[3:] if v.strip()]
                
                if values:
                    # Calculate the z-score: (observed - expected) / std_dev
                    # For GCP data: expected = 100, std_dev = 7.071
                    z_values = [(v - 100) / 7.071 for v in values]
                    abs_z_mean = np.mean([abs(z) for z in z_values])
                    data_rows.append({'timestamp': timestamp, 'abs_z_mean': abs_z_mean})
        
        if not data_rows:
            print(f"  - {year}-{month:02d}-{day:02d}: No valid data rows found")
            return None
            
        return pd.DataFrame(data_rows)
        
    except Exception as e:
        print(f"  - {year}-{month:02d}-{day:02d}: Download/processing failed ({e})")
        return None


def fetch_sample_days(year: int, num_days: int = 6) -> float:
    """Fetch a sample of days from each year (one day from every other month)
    
    Args:
        year: Year to fetch
        num_days: Number of days to sample per year
        
    Returns:
        Average absolute z-value or None if all downloads failed
    """
    # Sample one day from every other month (or adjust for desired sampling)
    # We use the 15th of each sampled month for consistency
    months = [1, 3, 5, 7, 9, 11][:num_days]
    day = 15  # Middle of the month
    
    all_data = []
    successful_days = 0
    
    for month in months:
        # Check if the date is valid (not in the future)
        today = dt.datetime.now()
        if dt.datetime(year, month, day) > today:
            print(f"  - {year}-{month:02d}-{day:02d}: Future date, skipping")
            continue
            
        # Add a slight delay to avoid overwhelming the server
        time.sleep(0.5)
        
        # Fetch the data
        df = fetch_day_data(year, month, day)
        if df is not None:
            all_data.append(df)
            successful_days += 1
            print(f"  - {year}-{month:02d}-{day:02d}: Success ({len(df)} samples)")
    
    # If we got data for at least one day, calculate the average
    if successful_days > 0:
        # Combine all the data and calculate the average
        combined_df = pd.concat(all_data, ignore_index=True)
        return float(combined_df['abs_z_mean'].mean())
    else:
        return None


def calculate_z_from_cumulative_variance(chi_squares: List[float], n_samples: int) -> float:
    """Calculate overall Z-score from chi-square values using GCP methodology.
    
    This follows the GCP method for aggregating data across multiple trials.
    
    Args:
        chi_squares: List of chi-square values
        n_samples: Number of samples
        
    Returns:
        Z-score based on cumulative variance
    """
    # Sum of chi-squares
    sum_chi = sum(chi_squares)
    
    # Expected value and standard deviation for the chi-square distribution
    # Degrees of freedom = number of samples
    expected = n_samples
    std_dev = np.sqrt(2 * n_samples)
    
    # Calculate Z-score as normalized deviation
    z_score = (sum_chi - expected) / std_dev
    
    return z_score


def main() -> None:
    first_year = 1998
    last_complete_year = dt.datetime.utcnow().year - 1

    print(f"‚è≥ Collecting RNG data samples ({first_year}‚Äì{last_complete_year})")
    results: Dict[int, float] = {}

    for year in tqdm(range(first_year, last_complete_year + 1)):
        print(f"\nProcessing year {year}:")
        z_value = fetch_sample_days(year)
        
        if z_value is None:
            z_value = FALLBACK.get(year)
            msg = "fallback" if z_value is not None else "missing"
            print(f"  - {year}: {msg}" + (f" ({z_value:.3f})" if z_value else ""))
        else:
            print(f"  - {year}: {z_value:.3f}")
            
        if z_value is not None:
            results[year] = round(z_value, 3)

    if not results:
        print("‚ÄºÔ∏è  No data obtained; exiting.", file=sys.stderr)
        sys.exit(1)

    out_path = DATA_DIR / "rng_direct_avg_abs_z.csv"
    pd.Series(results, name="avg_abs_z").sort_index().to_csv(out_path, header=True)
    print(f"‚úÖ  Wrote {out_path}  ({len(results)} rows)")
    
    # Update the configuration to use the direct data file
    print(f"üìù To use this data, update the EnhancedRngPattern class to look for 'rng_direct_avg_abs_z.csv'")


if __name__ == "__main__":
    main() 